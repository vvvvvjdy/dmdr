<h1 align="center"> DMDR:<br>Distribution Matching Distillation Meets  Reinforcement Learning</h1>
<div align="center">
  <a href='https://arxiv.org/abs/2511.13649'><img src='https://img.shields.io/badge/ArXiv-red?logo=arxiv'></a>  &nbsp;
  <a href="https://github.com/vvvvvjdy/dmdr"><img src="https://img.shields.io/badge/GitHub(DMDR)-9E95B7?logo=github"></a> &nbsp;
</div>


---


<p align="center">
   <figcaption style="text-align: center; margin-top: 10px; font-size: 0.95em;">
            Images generated by Z-Image-Turbo.
        </figcaption>
  <img src="assets/demo_pic_z.png" alt="Result" style="width:100%;">
</p>

---





<p align="center">
   <figcaption style="text-align: center; margin-top: 10px; font-size: 0.95em;">
            Images generated by SD3.5 Large finetuned through DMDR with open-source data and reward model using  4 NFE.
        </figcaption>
  <img src="assets/demo_pic_sd35.png" alt="Result" style="width:92%;">
</p>

---




## üåü Inference

**8 step Z-Image-Turbo generation (distilled by Decoupled-DMD and DMDR)**

See [Z-Image](https://github.com/Tongyi-MAI/Z-Image) repo.
  




## üå† Training 

We now only have access to open the training demo code of ImageNet, hoping it can help the community to understand DMDR!

Refer to [SiT (class-conditional generation on ImageNet)](train_cc/sit/README.md) for training few-step SiT diffusion model.



## ü•Ç Other Research of Our Team

- **[Decoupled DMD](https://arxiv.org/abs/2511.22677)**: Rethinking how DMD works and  revealing a functional decoupling
strategy with CFG Augmentation (CA) as the primary engine for few-step conversion and Distribution
Matching (DM) as the regularizer. 


## ü§ùüèª Acknowledgement

This code is mainly built upon [DMD2](https://github.com/tianweiy/DMD2), [SRA](https://github.com/vvvvvjdy/SRA),  [ReFL](https://github.com/zai-org/ImageReward), repositories. 
Thanks for  their contributions to the community.

We also sincerely thank the opensource weights from  [REPA](https://github.com/sihyun-yu/REPA), [DINOv2](https://github.com/facebookresearch/dinov2) and so on. 
We only use these weights and data for research purpose.


## üå∫ Citation
If you find DMDR useful, please kindly cite our paper:
```bibtex
@article{jiang2025dmdr,
title={Distribution Matching Distillation Meets Reinforcement Learning},
author={Jiang, Dengyang and Liu, Dongyang and Wang, Zanyi and Wu, Qilong and Jin, Xin and Liu, David and Li, Zhen and Wang, Mengmeng and Gao, Peng and Yang, Harry},
journal={arXiv preprint arXiv:2511.13649},
year={2025}
}
```
